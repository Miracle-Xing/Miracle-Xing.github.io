<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>邢大强的blog</title>
  
  <subtitle>Stay hungry. Stay foolish.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://miracle-xing.github.io/"/>
  <updated>2019-07-21T17:24:16.439Z</updated>
  <id>https://miracle-xing.github.io/</id>
  
  <author>
    <name>Miracle</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark 概念及应用程序架构</title>
    <link href="https://miracle-xing.github.io/2019/07/22/Spark-%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%9E%B6%E6%9E%84/"/>
    <id>https://miracle-xing.github.io/2019/07/22/Spark-概念及应用程序架构/</id>
    <published>2019-07-21T16:47:55.000Z</published>
    <updated>2019-07-21T17:24:16.439Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ol><li><p>Spark是计算框架，不是存储框架。类似Hadoop中的MR</p></li><li><p>Spark是分布式的内存计算框架，Spark在计算的时候，内存不够用，数据会写到磁盘。</p><a id="more"></a></li><li><p>Spark和Hadoop没有必然联系，两者是独立的。</p></li><li><p>Spark可以读取HDFS / fileSystem / DB / Kafka / Flume上的数据，可以把数据写到HDFS / fileSystem / DB / Kafka / Flume中。</p></li><li><p>Spark可以使用YARN做资源调度管理器 Spark on YARN。</p></li><li><p><strong>数据不动代码动</strong>。</p></li><li><p>Spark架构：Master Slave架构，主从架构，一主多从。</p></li><li><p>主从架构的突出问题是 <strong>单点故障</strong>，HA（高可用）架构就是为了解决单点故障，心跳消息。</p></li><li><p>主主架构：Flume，Kafka</p></li><li><p>数据本地性：计算时从最近的节点读取数据。</p></li><li><p>粗粒度、细粒度<br>指的是资源分配方式。<br>粗粒度：应用启动，资源就分配给你，你用不用都是你的。<br>细粒度：不提前分配资源，你需要的时候再给你。</p></li><li><p>Spark两种算子 <strong>Transformation</strong> 和 <strong>Action</strong><br>Transformation算子返回值是 RDD，Action算子返回值是计算结果，不是RDD。</p></li><li><p>Spark 有四种部署方式：Standalone / Spark on YARN / Apache Mesos / Kubernetes</p></li><li><p>Spark Shell 是Spark提供的本地交互式脚本，默认启动时Local模式，使用Scala语言。</p></li></ol><p><strong>Scala 一行代码实现 wordcount</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">textFile.flatMap(line=&gt;line.split(&quot; &quot;)).map(word=&gt;(word,1)).reduceByKey(_+_).sortBy(_._2,false).collect().foreach(println)</span><br></pre></td></tr></table></figure><hr><h1 id="Spark-应用程序架构"><a href="#Spark-应用程序架构" class="headerlink" title="Spark 应用程序架构"></a>Spark 应用程序架构</h1><ol><li><p>Spark 应用程序组件：driver, the master, the cluster manager 和运行在worker节点的executor(s)<br><img src="/images/2019/07/22/42616bf0-abd7-11e9-87f2-3dee39091945.png" alt="Spark 应用程序架构.png"><br>所有Spark组件，包括 driver, master 和 executor进程，都在JVM中运行。使用Scala编写的Spark程序编译为Java字节码在JVM上运行。</p></li><li><p>区分Spark运行时应用程序组件 和运行它们的位置和节点类型是很重要的。使用不同的部署模式，这些组件可能运行在不同的位置，所以不要以物理节点或实例的形式考虑这些组件。</p></li></ol><h2 id="1-Spark-Driver"><a href="#1-Spark-Driver" class="headerlink" title="1.  Spark Driver"></a>1.  Spark Driver</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;Spark 应用程序由一个 driver 进程（驱动程序）和一组 executor 进程组成。Spark 应用程序的生命周期从 Spark Driver 程序开始（和结束）。driver 进程负责运行你的 main 函数，此进程位于集群中的一个 节点上。主要负责三件事：</p><ol><li>维护有关 Spark 应用程序的信息；</li><li>响应用户的程序或输入；</li><li>分配和调度 executor 的 task 和资源。</li></ol><p>executors 进程实际执行 driver 分配给他们的工作。这意味着每个 executor 主要负责两件事：</p><ol><li>执行由驱动程序分配给它的代码。</li><li>将执行器 executor 的计算状态报告给 driver 节点。</li></ol><h3 id="1-1-SparkContext"><a href="#1-1-SparkContext" class="headerlink" title="1.1 SparkContext"></a>1.1 SparkContext</h3><p>Spark Driver 程序负责创建 SparkContext。 SparkContext 在 Spark Shell 中对应的变量名为 sc，用于连接 Spark 集群，是与 Spark 集群交互的入口。SparkContext 在 Spark 应用程序（包括 Spark Shell）的开始实例化，并用于整个程序。</p><h3 id="1-2-应用程序执行计划"><a href="#1-2-应用程序执行计划" class="headerlink" title="1.2 应用程序执行计划"></a>1.2 应用程序执行计划</h3><p>Driver 程序的主要功能之一是规划应用程序的执行。驱动程序接受所有请求的 transformation 和 action 操作，并创建一个有向无环图（DAG）。<br><strong>注</strong>：DAG  是计算机科学中常用的表示数据流及其依赖关系的数学结构。DAGs 包含节点和边，节点表示执行计划中的步骤。DAG中的边以定向的方式将一个节点连接到另一个顶点，这样就不会出现 循环引用。</p><p>DAG 由 task 和 stages 组成。task 是 Spark 程序中可调度工作的最小单位。stage是一组可以一起运行的task。多个stage之间是相互依存的 。shuffle是划分stage的依据。</p><p>在进程调度意义上，DAGs 并不是 Spark 独有的。例如，它们被用于其他大数据生态系统项目，如 Tez、Drill 和 Presto 的任务调度。DAGs 是 Spark 的基础！！！</p><h3 id="1-3-应用程序的调度"><a href="#1-3-应用程序的调度" class="headerlink" title="1.3 应用程序的调度"></a>1.3 应用程序的调度</h3><p>driver 程序还协调 DAG 中定义的 stage 和 task 的运行。在调度和运行 task 时涉及的主要driver 程序活动包括：</p><ul><li>跟踪可用资源以执行 task</li><li>调度任务，以便在可能的情况下 “接近”数据运行——数据本地性</li><li>协调数据在 stages 之间的移动</li></ul><h3 id="1-4-其他功能"><a href="#1-4-其他功能" class="headerlink" title="1.4 其他功能"></a>1.4 其他功能</h3><p>除了计划和编排 Spark 程序的执行之外，驱动程序还负责从应用程序返回结果。<br>driver 程序在4040端口上自动创建了应用程序 UI。如果在同一个主机上启动后续应用程序，则会为应用程序 UI 使用连续的端口（例如 4041, 4042 等）。</p><h2 id="2-Executor-和-worker"><a href="#2-Executor-和-worker" class="headerlink" title="2. Executor 和 worker"></a>2. Executor 和 worker</h2><p>Spark executor 是运行来自 Spark DAG 的task 进程。executor 在 Spark 集群中的worker 节点上获取 CPU和内存等计算资源。executor 专用于特定的 Spark 应用程序，并在 应用程序完成时终止。在 Spark 程序中，Spark executor 可以运行成百上千个 task。</p><p>通常情况下，worker 节点（承载 executor 进程）具有有限或固定数量的 executor。因此，一个 spark 集群（包括一定数量的服务器节点）具有有限数量的 executor，可以分配它们来运行 Spark 任务。</p><p>Spark executor 驻留在 JVM 中。executor 的 JVM 分配了一个堆内存，这是一个用于存储和管理对象的专用内存空间。堆内存的大小由 spark 配置文件 spark-default.xml 中的 spark.executor.memory 属性确定，或者 由提交应用程序时 spark-submit 的参数 –executor-memroy  确定。</p><p>worker 和 executor 只知道分配给他们的 task，而 driver 程序负责理解组成应用程序的完整 task 集合它们各自的依赖关系。</p><h2 id="3-Master-和-Cluster-Manager"><a href="#3-Master-和-Cluster-Manager" class="headerlink" title="3. Master 和 Cluster Manager"></a>3. Master 和 Cluster Manager</h2><p>Spark driver 程序计划并协调运行 Spark 应用程序所需的 task 集。task 本身在 executor 中运行，executor 驻留在 worker 节点上。</p><p>Master 和 Cluster Manager 是监控、分配、回收集群（Executor 运行的节点）资源的核心进程，Master 和 Cluster Manager 可以是各自独立的进程（Spark On YARN），也可以组合成一个进程（Standalone 运行模式）。</p><h3 id="3-1-Master"><a href="#3-1-Master" class="headerlink" title="3.1 Master"></a>3.1 Master</h3><p>Spark master 是用于请求集群中的资源并将这些资源提供给 Spark driver 程序的进程。在两种部署模式中，master 节点都与 worker 节点或slave 节点协商资源或容器，并跟踪 它们的状态并监视它们的进展。</p><p>Spark master 进程在 master 进程所在主机上的端口 8080 上，提供 web 用户界面。</p><p><strong>注</strong>：要区分 driver 进程和 master 进程在 Spark 程序运行时的作用。master 只是请求 资源，并使这些资源在应用程序的生命周期内对驱动程序可用。尽管 master 监控这些资源的状态和健康状况，但是它不参与应用程序的执行以及 task 和 stage 的协调。</p><h3 id="3-2-Cluster-Manager（集群管理器）"><a href="#3-2-Cluster-Manager（集群管理器）" class="headerlink" title="3.2 Cluster Manager（集群管理器）"></a>3.2 Cluster Manager（集群管理器）</h3><p>Cluster Manager 进程负责监控分配给 worker 节点上的资源，这些资源是 master 进程请求分配的。然后，master 以 Executor 的形式将这些集群资源提供给 driver 程序。如前所述，Cluster Manager可以独立于 master 进程（Spark On YARN），也可以组合成一个进程（Standalone 运行模式）。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Spark是计算框架，不是存储框架。类似Hadoop中的MR&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Spark是分布式的内存计算框架，Spark在计算的时候，内存不够用，数据会写到磁盘。&lt;/p&gt;
    
    </summary>
    
    
      <category term="笔记" scheme="https://miracle-xing.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
