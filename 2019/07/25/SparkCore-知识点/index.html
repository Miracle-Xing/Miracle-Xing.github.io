<!DOCTYPE html>


  <html class="light page-post">


<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>SparkCore 知识点 | 邢大强的blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Spark,SparkCore,">
  

  <meta name="description" content="1. Spark 共享变量实战通常，Spark 程序计算的时候，我们传递的函数时在远程集群节点上执行的，在函数中使用的所有变量副本会传递到远程节点，计算任务使用变量副本进行计算。这些变量被复制到每台机器上，对远程机器上的变量的更新不会返回 driver 程序。 跨任务支持通用的读写共享变量将是低效的。但是，Spark 为两种常见的使用模式提供了两种有限 功能的共享变量：广播变量 和 累加器。">
<meta name="keywords" content="Spark,SparkCore">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkCore 知识点">
<meta property="og:url" content="https://miracle-xing.github.io/2019/07/25/SparkCore-知识点/index.html">
<meta property="og:site_name" content="邢大强的blog">
<meta property="og:description" content="1. Spark 共享变量实战通常，Spark 程序计算的时候，我们传递的函数时在远程集群节点上执行的，在函数中使用的所有变量副本会传递到远程节点，计算任务使用变量副本进行计算。这些变量被复制到每台机器上，对远程机器上的变量的更新不会返回 driver 程序。 跨任务支持通用的读写共享变量将是低效的。但是，Spark 为两种常见的使用模式提供了两种有限 功能的共享变量：广播变量 和 累加器。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/20923920-ae19-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/2f0d3180-ae19-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/8d693ad0-ae19-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/db3c0530-ae19-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/e80555f0-ae19-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/fb0fe890-ae19-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/008527e0-ae1a-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/04841ae0-ae1a-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/0deefe60-ae1a-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/14ce5500-ae1a-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/24/19130390-ae1a-11e9-8908-0b6e2efa6f40.png">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/25/81920210-aea4-11e9-8908-0b6e2efa6f40.png">
<meta property="og:updated_time" content="2019-08-29T18:43:43.474Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SparkCore 知识点">
<meta name="twitter:description" content="1. Spark 共享变量实战通常，Spark 程序计算的时候，我们传递的函数时在远程集群节点上执行的，在函数中使用的所有变量副本会传递到远程节点，计算任务使用变量副本进行计算。这些变量被复制到每台机器上，对远程机器上的变量的更新不会返回 driver 程序。 跨任务支持通用的读写共享变量将是低效的。但是，Spark 为两种常见的使用模式提供了两种有限 功能的共享变量：广播变量 和 累加器。">
<meta name="twitter:image" content="https://miracle-xing.github.io/images/2019/07/24/20923920-ae19-11e9-8908-0b6e2efa6f40.png">

  

  
    <link rel="icon" href="/assets/img/m.png">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    <link rel="stylesheet" href="/css/personal-style.css">
  

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-38189205-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?57e94d016e201fba3603a8a2b0263af0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>
</html>
<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">盒子</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/atom.xml"
            rel="noopener noreferrer"
            target="_blank"
            >
            RSS
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Spark-共享变量实战"><span class="toc-text">1. Spark 共享变量实战</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-广播变量-Broadcast-Variables"><span class="toc-text">1.1 广播变量 Broadcast Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-累加器-Accumulator"><span class="toc-text">1.2 累加器 Accumulator</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-注意使用累加器的陷阱"><span class="toc-text">1.2.1 注意使用累加器的陷阱</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-2-累加器和广播变量的不同"><span class="toc-text">1.2.2 累加器和广播变量的不同</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Spark-应用程序调度过程"><span class="toc-text">2. Spark 应用程序调度过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Client-提交-Job-Driver-会向-master-申请资源，master-收到请求之后，会向-worker-进行资源调度，启动-Executor，然后，Executor-向-Driver-进行注册。"><span class="toc-text">2.1 Client 提交 Job, Driver 会向 master 申请资源，master 收到请求之后，会向 worker 进行资源调度，启动 Executor，然后，Executor 向 Driver 进行注册。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-此时Spark-应用程序就会知道哪些-worker-上面的-executor-已经就绪。接着开始执行-spark-任务："><span class="toc-text">2.2 此时Spark 应用程序就会知道哪些 worker 上面的 executor 已经就绪。接着开始执行 spark 任务：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-从-Spark-集群角度（静态）："><span class="toc-text">2.3 从 Spark 集群角度（静态）：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-Master"><span class="toc-text">2.3.1 Master</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-Worker"><span class="toc-text">2.3.2 Worker</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-从-Spark-应用程序的角度（动态）："><span class="toc-text">2.4 从 Spark 应用程序的角度（动态）：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-1-Application"><span class="toc-text">2.4.1 Application</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-2-Driver"><span class="toc-text">2.4.2 Driver</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-3-Action"><span class="toc-text">2.4.3 Action</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-4-Transformation"><span class="toc-text">2.4.4 Transformation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-5-Job"><span class="toc-text">2.4.5 Job</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-6-Stage"><span class="toc-text">2.4.6 Stage</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-7-Task"><span class="toc-text">2.4.7 Task</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-8-Executor"><span class="toc-text">2.4.8 Executor</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Spark-Master-高可用配置-HA"><span class="toc-text">3. Spark Master 高可用配置 HA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Standby-Masters-with-ZooKeeper"><span class="toc-text">3.1 Standby Masters with ZooKeeper</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-1-概述"><span class="toc-text">3.1.1 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-2-配置"><span class="toc-text">3.1.2 配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-3-可能的陷阱"><span class="toc-text">3.1.3 可能的陷阱</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-4-详细"><span class="toc-text">3.1.4 详细</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-5-HA-配置实战"><span class="toc-text">3.1.5 HA 配置实战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-带有本地文件系统的单节点恢复"><span class="toc-text">3.2 带有本地文件系统的单节点恢复</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-概述"><span class="toc-text">3.2.1 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-配置"><span class="toc-text">3.2.2 配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-细节"><span class="toc-text">3.2.3 细节</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Spark-应用程序内存和-CPU-的分配"><span class="toc-text">4. Spark 应用程序内存和 CPU 的分配</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-Spark-运行模式"><span class="toc-text">4.1 Spark 运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-1-local"><span class="toc-text">4.1.1 local</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-2-standalone"><span class="toc-text">4.1.2 standalone</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-3-yarn"><span class="toc-text">4.1.3 yarn</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-4-mesos"><span class="toc-text">4.1.4 mesos</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-如何设置-Spark-配置属性"><span class="toc-text">4.2 如何设置 Spark 配置属性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-有三种方式设置spark-的配置属性"><span class="toc-text">4.2.1 有三种方式设置spark 的配置属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-典型的-spark-defaults-conf-文件内容"><span class="toc-text">4.2.2 典型的 spark-defaults.conf 文件内容</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-集群资源配置实战"><span class="toc-text">4.3 集群资源配置实战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-Spark-应用程序-资源配置实战"><span class="toc-text">4.4 Spark 应用程序 资源配置实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-1-–executor-cores"><span class="toc-text">4.4.1 –executor-cores</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-2-参数优先级"><span class="toc-text">4.4.2 参数优先级</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-3-几个常用的配置项"><span class="toc-text">4.4.3 几个常用的配置项</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Spark-on-yarn"><span class="toc-text">5. Spark on yarn</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-概述"><span class="toc-text">5.1 概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-资源分配"><span class="toc-text">5.2 资源分配</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-1-CPU-的分配"><span class="toc-text">5.2.1 CPU 的分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-2-内存的分配"><span class="toc-text">5.2.2 内存的分配</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-如何给-Spark-分配资源"><span class="toc-text">5.3 如何给 Spark 分配资源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-Spark-应用资源分配的限制"><span class="toc-text">5.4 Spark 应用资源分配的限制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-spark-on-yarn-应用的提交方式"><span class="toc-text">5.5 spark on yarn 应用的提交方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-6-Spark-on-yarn-的资源分配依赖于-spark-的运行模式"><span class="toc-text">5.6 Spark on yarn 的资源分配依赖于 spark 的运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-1-为-spark-driver-分配资源"><span class="toc-text">5.6.1 为 spark driver 分配资源</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-7-Client-模式下-AM、Driver-的资源分配"><span class="toc-text">5.7 Client 模式下 AM、Driver 的资源分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-8-Cluster-模式下-AM、Driver-的资源分配"><span class="toc-text">5.8 Cluster 模式下 AM、Driver 的资源分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-9-Executor-的资源配置"><span class="toc-text">5.9 Executor 的资源配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-10-Spark-内存使用"><span class="toc-text">5.10 Spark 内存使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-10-1-Spark-如何使用内存"><span class="toc-text">5.10.1 Spark 如何使用内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-10-2-Spark-内存使用的配置"><span class="toc-text">5.10.2 Spark 内存使用的配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-10-3-一个-Executor-究竟能使用多少内存？"><span class="toc-text">5.10.3 一个 Executor 究竟能使用多少内存？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-10-4-发现当前内存使用量"><span class="toc-text">5.10.4 发现当前内存使用量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-10-5-需要记住的几点"><span class="toc-text">5.10.5 需要记住的几点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-11-Client-模式还是-Cluster-模式"><span class="toc-text">5.11 Client 模式还是 Cluster 模式</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-SparkCore-知识点" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">SparkCore 知识点</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.07.25</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>Miracle</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/笔记/">笔记</a>
  </span>



      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <h1 id="1-Spark-共享变量实战"><a href="#1-Spark-共享变量实战" class="headerlink" title="1. Spark 共享变量实战"></a>1. Spark 共享变量实战</h1><p>通常，Spark 程序计算的时候，我们传递的函数时在远程集群节点上执行的，在函数中使用的所有<strong>变量副本</strong>会传递到远程节点，计算任务使用<strong>变量副本</strong>进行计算。这些变量被复制到每台机器上，对远程机器上的变量的更新不会返回 driver 程序。</p>
<p>跨任务支持通用的读写共享变量将是低效的。但是，Spark 为两种常见的使用模式提供了两种有限 功能的共享变量：<strong>广播变量</strong> 和 <strong>累加器</strong>。</p>
<a id="more"></a>
<h2 id="1-1-广播变量-Broadcast-Variables"><a href="#1-1-广播变量-Broadcast-Variables" class="headerlink" title="1.1 广播变量 Broadcast Variables"></a>1.1 广播变量 Broadcast Variables</h2><p>广播变量允许 Spark 程序员将 <strong>只读变量</strong> 缓存在每台机器上，而不是将它的副本与 task 一起发送出去。例如，可以使用广播变量以高效的方式为每个 worker 节点提供一个大型输入数据集的副本。广播变量是只读的，对每个 worker 节点只需要传输一次。这样，就从每个 task 一份变量副本 ，变成了 <strong>一个 executor 一个变量副本</strong>，executor 中执行的 task 共用这个副本。如果有多个 worker 节点，<strong>各个 worker 上的 executor 中的变量副本并不都是来自 driver</strong>，因为 Spark 采用了高效地广播算法（TorrentBroadcast）来分配广播变量，以降低通信成本。</p>
<p><strong>代码片段</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">    val list1=List((&quot;zhangsan&quot;,20),(&quot;lisi&quot;,18),(&quot;wangwu&quot;,30))</span><br><span class="line">    val list2=List((&quot;zhangsan&quot;,&quot;Math&quot;),(&quot;lisi&quot;,&quot;English&quot;),(&quot;wangwu&quot;,&quot;Science&quot;))</span><br><span class="line"></span><br><span class="line">    val rdd1=sc.parallelize(list1)</span><br><span class="line">    val rdd2=sc.parallelize(list2)</span><br><span class="line"></span><br><span class="line">    // 直接join会进行shuffle，导致性能低下</span><br><span class="line">//    val joinRDD=rdd1.join(rdd2)</span><br><span class="line">//    joinRDD.foreach(println)</span><br><span class="line"></span><br><span class="line">    // 可以将较小的rdd广播出去</span><br><span class="line">    val rddData=rdd1.collectAsMap()</span><br><span class="line">    val rddBC=sc.broadcast(rddData)</span><br><span class="line">    val rdd3=rdd2.mapPartitions(partition=&gt;&#123;</span><br><span class="line">      val bc=rddBC.value</span><br><span class="line">      for&#123;</span><br><span class="line">        (key,value)&lt;-partition</span><br><span class="line">        if(rddData.contains(key))</span><br><span class="line">      &#125;yield (key,bc.get(key).getOrElse(&quot;&quot;),value)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    rdd3.foreach(t=&gt;println(t._1+&quot;,&quot;+t._2+&quot;,&quot;+t._3))</span><br></pre></td></tr></table></figure>

<h2 id="1-2-累加器-Accumulator"><a href="#1-2-累加器-Accumulator" class="headerlink" title="1.2 累加器 Accumulator"></a>1.2 累加器 Accumulator</h2><ol>
<li><p>顾名思义，累加器是只能 累加的变量。在 task 中只能对累加器进行添加数值，而不能获取累加器的值。<strong>累加器只能在 driver 端获取</strong>。</p>
</li>
<li><p>累加器支持加法交换律和结合律，因此 可以有效的支持 spark task 的并行计算。</p>
</li>
<li><p>累加器可用于 Spark 任务<strong>计数场景</strong>或者 Spark 任务<strong>求和场景</strong>。Spark 内置了几种累加器，支持自定义累加器。作为 Spark 开发工程师，可以创建命名的或未命名的累加器。如下所示，一个命名累加器（在这个实例计数器 中）将显示在修改该累加器的 stage web UI 中。</p>
</li>
<li><p>Spark 显示 “Tasks”表中由任务修改的每个累加器的值。<br><img src="/images/2019/07/24/20923920-ae19-11e9-8908-0b6e2efa6f40.png" alt="累加器.png"></p>
</li>
</ol>
<h3 id="1-2-1-注意使用累加器的陷阱"><a href="#1-2-1-注意使用累加器的陷阱" class="headerlink" title="1.2.1 注意使用累加器的陷阱"></a>1.2.1 注意使用累加器的陷阱</h3><ol>
<li>执行多个 action !!</li>
<li>Task 缓存数据被踢出时，下次用到时，会重新计算，此时累加器会重复计数。综上，实际项目中，累加器仅用于程序调试。</li>
</ol>
<p><strong>代码片段</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">AccumulatorV2&lt;Long, Long&gt; longAccumulator = jsc.sc().longAccumulator(&quot;longAccumulator&quot;);</span><br><span class="line">JavaRDD&lt;String&gt; javaRDD = jsc.textFile(&quot;in/README.md&quot;);</span><br><span class="line">JavaRDD&lt;String&gt; map = javaRDD.map(line -&gt; &#123;</span><br><span class="line">    longAccumulator.add(Long.valueOf(1));</span><br><span class="line">    return line.toUpperCase();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">// 执行 action 操作才会执行以上 transformation</span><br><span class="line">map.count();</span><br><span class="line">System.out.println(&quot;count: &quot; + javaRDD.count());</span><br><span class="line">System.out.println(&quot;i: &quot; + longAccumulator.value());</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>：</p>
<blockquote>
<p>count: 103<br>i: 103</p>
</blockquote>
<h2 id="1-2-2-累加器和广播变量的不同"><a href="#1-2-2-累加器和广播变量的不同" class="headerlink" title="1.2.2 累加器和广播变量的不同"></a>1.2.2 累加器和广播变量的不同</h2><ol>
<li><p>广播变量一般用于 Spark 程序调优，如果不使用广播变量，程序计算结果不会错误，只是性能可能低下。</p>
</li>
<li><p>累加器不同，如果应该使用累加器的场景，你不使用，此时，程序计算结果就是错误的。</p>
</li>
</ol>
<h1 id="2-Spark-应用程序调度过程"><a href="#2-Spark-应用程序调度过程" class="headerlink" title="2. Spark 应用程序调度过程"></a>2. Spark 应用程序调度过程</h1><p><img src="/images/2019/07/24/2f0d3180-ae19-11e9-8908-0b6e2efa6f40.png" alt="spark 应用程序调度过程.png"></p>
<h2 id="2-1-Client-提交-Job-Driver-会向-master-申请资源，master-收到请求之后，会向-worker-进行资源调度，启动-Executor，然后，Executor-向-Driver-进行注册。"><a href="#2-1-Client-提交-Job-Driver-会向-master-申请资源，master-收到请求之后，会向-worker-进行资源调度，启动-Executor，然后，Executor-向-Driver-进行注册。" class="headerlink" title="2.1 Client 提交 Job, Driver 会向 master 申请资源，master 收到请求之后，会向 worker 进行资源调度，启动 Executor，然后，Executor 向 Driver 进行注册。"></a>2.1 Client 提交 Job, Driver 会向 master 申请资源，master 收到请求之后，会向 worker 进行资源调度，启动 Executor，然后，Executor 向 Driver 进行注册。</h2><h2 id="2-2-此时Spark-应用程序就会知道哪些-worker-上面的-executor-已经就绪。接着开始执行-spark-任务："><a href="#2-2-此时Spark-应用程序就会知道哪些-worker-上面的-executor-已经就绪。接着开始执行-spark-任务：" class="headerlink" title="2.2 此时Spark 应用程序就会知道哪些 worker 上面的 executor 已经就绪。接着开始执行 spark 任务："></a>2.2 此时Spark 应用程序就会知道哪些 worker 上面的 executor 已经就绪。接着开始执行 spark 任务：</h2><ol>
<li><p>遇到 action 操作—&gt; 创建一个 job—&gt; 提交给 DAGScheduler，DAGScheduler 会 把 Job分为多个 stages（shuffle: 最后一个 stage 里面的 task 叫 ResultTask，前面 stage 里面的 task 叫 ShuffleMapTask），为每个 stage 创建 一个 taskset 集合，集合中的 task 计算逻辑完全 相同，只是处理的数据不同。Task 的数量等于 partition 的数量，但是同时执行的 task  的数量等于集群 core 的数量。整个 Application 运行完成时间，等于最后一个执行完成的 task 的时间。（数据倾斜问题）</p>
</li>
<li><p>然后 DAGScheduler 会把 taskset 交给 TaskScheduler ，TaskScheduler 会把 taskset 里面的 task 发送给 Executor。Executor 接收到 task，会启动一个线程池 TaskRunner，在里面运行 task。</p>
</li>
</ol>
<blockquote>
<p>spark-submit –master spark://bigdata01:7077 –class sparkcore.learnTextFile<br>F:\train\data\sparkapp\learnTextFile.jar</p>
</blockquote>
<h2 id="2-3-从-Spark-集群角度（静态）："><a href="#2-3-从-Spark-集群角度（静态）：" class="headerlink" title="2.3 从 Spark 集群角度（静态）："></a>2.3 从 Spark 集群角度（静态）：</h2><h3 id="2-3-1-Master"><a href="#2-3-1-Master" class="headerlink" title="2.3.1 Master"></a>2.3.1 Master</h3><p>standalone 模式下的集群管理器，负责资源的分配。相当于 YARN 模式下的 ResourceManager。</p>
<h3 id="2-3-2-Worker"><a href="#2-3-2-Worker" class="headerlink" title="2.3.2 Worker"></a>2.3.2 Worker</h3><p>集群中任何可以运行 Application 代码的节点，类似于 YARN 中的 NodeManager 节点。在 Standalone 模式中指的就是通过 Slave 文件配置的 Worker 节点，在 Spark on YARN 模式中指的就是 NodeManager 节点。</p>
<h2 id="2-4-从-Spark-应用程序的角度（动态）："><a href="#2-4-从-Spark-应用程序的角度（动态）：" class="headerlink" title="2.4 从 Spark 应用程序的角度（动态）："></a>2.4 从 Spark 应用程序的角度（动态）：</h2><h3 id="2-4-1-Application"><a href="#2-4-1-Application" class="headerlink" title="2.4.1 Application"></a>2.4.1 Application</h3><p>Spark 应用程序，包含 Driver 功能代码和分布在集群中多个节点上运行的 Executor 代码。</p>
<h3 id="2-4-2-Driver"><a href="#2-4-2-Driver" class="headerlink" title="2.4.2 Driver"></a>2.4.2 Driver</h3><p>运行 Application 的 main() 函数并创建 SparkContext，其中创建 SparkContext 的目的是为了准备 Spark 应用程序的运行环境。在Spark 中有 SparkContext 负责和 ClusterManager 通信，进行资源的申请、任务的分配和监控等。当 Executor 部分运行完毕后， Driver 负责将 SparkContext 关闭。</p>
<h3 id="2-4-3-Action"><a href="#2-4-3-Action" class="headerlink" title="2.4.3 Action"></a>2.4.3 Action</h3><h3 id="2-4-4-Transformation"><a href="#2-4-4-Transformation" class="headerlink" title="2.4.4 Transformation"></a>2.4.4 Transformation</h3><h3 id="2-4-5-Job"><a href="#2-4-5-Job" class="headerlink" title="2.4.5 Job"></a>2.4.5 Job</h3><p>包含多个 Task 组成的并行计算，由 Spark Action 生成，一个 Job 包含多个 RDD 及作用于 RDD 上的各种 transformation。</p>
<h3 id="2-4-6-Stage"><a href="#2-4-6-Stage" class="headerlink" title="2.4.6 Stage"></a>2.4.6 Stage</h3><p>每个 Job 会被拆分很多组 Task，每组 task 被称为 Stage，也可称 TaskSet，一个作业分为多个 stage。</p>
<h3 id="2-4-7-Task"><a href="#2-4-7-Task" class="headerlink" title="2.4.7 Task"></a>2.4.7 Task</h3><p>被送到 Executor 上的工作任务，运行计算逻辑的地方。</p>
<h3 id="2-4-8-Executor"><a href="#2-4-8-Executor" class="headerlink" title="2.4.8 Executor"></a>2.4.8 Executor</h3><p>运行在 Worker 节点上的一个进程，该进程负责运行 Task，并且负责将数据存在内存或者磁盘上，每个 Application 都有各自独立的一批 Executor。</p>
<h1 id="3-Spark-Master-高可用配置-HA"><a href="#3-Spark-Master-高可用配置-HA" class="headerlink" title="3. Spark Master 高可用配置 HA"></a>3. Spark Master 高可用配置 HA</h1><p>默认情况下，Standalone 调度集群能够处理 worker 故障（通过将计算任务转移到其他 worker）。然而，调度器使用一个 Master 来做出调度决策，这（默认情况下）会产生一个单点故障问题：如果 Master 崩溃，就不能提交新的应用程序。为了克服这一点，有两个高可用性方案，详细如下。</p>
<h2 id="3-1-Standby-Masters-with-ZooKeeper"><a href="#3-1-Standby-Masters-with-ZooKeeper" class="headerlink" title="3.1 Standby Masters with ZooKeeper"></a>3.1 Standby Masters with ZooKeeper</h2><h3 id="3-1-1-概述"><a href="#3-1-1-概述" class="headerlink" title="3.1.1 概述"></a>3.1.1 概述</h3><p>使用 ZooKeeper 来提供 leader 选举和一些状态存储，您可以在集群中启动多个连接到同一个 ZooKeeper 实例的 master 服务器。其中一个将被选为“leader”，其他的将保持 standby 状态。如果当前的 leader  挂掉 ，将选举另一个 master 成为 leader，恢复旧 master 的状态，然后恢复调度工作。整个恢复过程需要 1 到 2 分钟。注意，这种延迟只影响调度新应用程序——在 master 故障转移期间已经运行的应用程序不受影响。</p>
<h3 id="3-1-2-配置"><a href="#3-1-2-配置" class="headerlink" title="3.1.2 配置"></a>3.1.2 配置</h3><p>为了启动这个恢复模式，您可以在 spark-env.sh 中设置 SPARK_DAEMON_JAVA_OPTS，配置 spark.deploy.recoveryMode 和 spark.deploy.zookeeper.* 相关的配置。参考： <a href="http://spark.apache.org/docs/latest/configuration.html#deploy" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/configuration.html#deploy</a></p>
<h3 id="3-1-3-可能的陷阱"><a href="#3-1-3-可能的陷阱" class="headerlink" title="3.1.3 可能的陷阱"></a>3.1.3 可能的陷阱</h3><p>如果您的集群中有多个 master，但是没有正确地配置 master 来使用 ZooKeeper，那么 master 将无法发现彼此，并认为他们都是 leader。这将不会导致一个健康的集群状态（因为所有 master 都将独立调度）。</p>
<h3 id="3-1-4-详细"><a href="#3-1-4-详细" class="headerlink" title="3.1.4 详细"></a>3.1.4 详细</h3><p>在设置了 ZooKeeper 集群之后，启用高可用性就很简单了。只需只用相同的 ZooKeeper 配置（ZooKeeper URL和目录）在不同的节点上启动多个 master 进程。master  可以在任何时候添加和删除。</p>
<p>为了安排新的应用程序或将 worker 添加到集群中，他们需要知道当前 leader master 的 IP 地址。这可以通过简单地传递一个 master URL 列表来实现，您以前在这些 master 列表中只传递一个 master URL。例如，您可以启动 SparkContext，指向spark://host1:port1,host2:port2。这将导致您的 SparkContext 尝试向两个 master 注册——如果 host1 宕机，这个配置仍然是正确的，因为我们将找到新的 leader: host2。</p>
<p>“注册到一个 Master 服务器”和正常 操作之间有一个重要的区别。在启动时，应用程序或 worker 需要能够找到并注册到当前的 master。但是，一旦注册成功，master 就是“在系统中”（即存储在 ZooKeeper）。如果发生故障转移，新 master leader 将联系所有以前注册的应用程序和 worker，通知他们 leader 的更改，因此他们在启动时甚至不需要知道新 master的存在。</p>
<p>由于这个属性，可以在任何时候创建新的 master，唯一需要担心的是，新的应用程序和 worker 可以找到它进行注册，以防它成为 leader。</p>
<h3 id="3-1-5-HA-配置实战"><a href="#3-1-5-HA-配置实战" class="headerlink" title="3.1.5 HA 配置实战"></a>3.1.5 HA 配置实战</h3><ol>
<li>spark-env.sh 配置（所有节点都需要配置）<blockquote>
<p>export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoveryMode=ZOOKEEPER </p>
</blockquote>
</li>
</ol>
<p>-Dspark.deploy.zookeeper.url=master01:2181master02:2181,slave01:2181,slave02:2181,slave03:2181<br>-Dspark.deploy.zookeeper.dir=/opt/modules/spark213/meta”</p>
<ol start="2">
<li><p>master01</p>
<blockquote>
<p>start.all.sh</p>
</blockquote>
</li>
<li><p>master02</p>
<blockquote>
<p>start-master.sh</p>
</blockquote>
</li>
<li><p>master01</p>
<blockquote>
<p>stop-master.sh</p>
</blockquote>
</li>
<li><p>查看 master 是否切换，standby-&gt;active</p>
</li>
</ol>
<h2 id="3-2-带有本地文件系统的单节点恢复"><a href="#3-2-带有本地文件系统的单节点恢复" class="headerlink" title="3.2 带有本地文件系统的单节点恢复"></a>3.2 带有本地文件系统的单节点恢复</h2><h3 id="3-2-1-概述"><a href="#3-2-1-概述" class="headerlink" title="3.2.1 概述"></a>3.2.1 概述</h3><p>ZooKeeper 是实现 产品级高可用性的最佳方法，但如果您只是想在 master 服务器宕机时重启它，那么文件系统模式 可以解决这个问题。当应用程序和工作者注册时，它们有足够的状态被写入到提供的目录中，以便在 master 进程重新启动时可以恢复它们。</p>
<h3 id="3-2-2-配置"><a href="#3-2-2-配置" class="headerlink" title="3.2.2 配置"></a>3.2.2 配置</h3><p>为了启动这个恢复模式，可以在 spark-env.sh 中设置 SPARK_DAEMON_JAVA_OPTS 的相关配置：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>spark.deploy.recoveryMode</td>
<td>将文件系统设置为启用单节点恢复莫斯（默认 ：无）</td>
</tr>
<tr>
<td>spark.deploy.recoveryDirectory</td>
<td>Spark 将存储恢复状态的目录，从 master 的角度进行访问</td>
</tr>
</tbody></table>
<h3 id="3-2-3-细节"><a href="#3-2-3-细节" class="headerlink" title="3.2.3 细节"></a>3.2.3 细节</h3><p>这个解决方案可以与进程监视器、管理器（如 monitor）一起使用，或者只是通过重新启动启用手动恢复。</p>
<p>虽然文件系统恢复看起来比不进行任何恢复要好得多，但是对于某些开发或实验目的来说，这种模式可能不是最优的。特别是，通过 kill master 来停止 master 不会清理它的恢复状态，所以无论何时启动一个新主，它都会进入恢复模式。如果需要等待所有以前注册的工人、客户端超时，这将使启动时间增加最多 1 分钟。</p>
<p>虽然 它不受官方支持，但您可以将 NFS 目录挂载为恢复目录。如果原始的 master 节点完全死亡，那么您可以在另一个节点 上启动一个主节点，它将正确地恢复所有以前注册的 worker、应用程序（相当于 ZooKeeper 恢复）。然而，为了注册，未来的应用程序必须能够找到新的主程序。</p>
<h1 id="4-Spark-应用程序内存和-CPU-的分配"><a href="#4-Spark-应用程序内存和-CPU-的分配" class="headerlink" title="4. Spark 应用程序内存和 CPU 的分配"></a>4. Spark 应用程序内存和 CPU 的分配</h1><h2 id="4-1-Spark-运行模式"><a href="#4-1-Spark-运行模式" class="headerlink" title="4.1 Spark 运行模式"></a>4.1 Spark 运行模式</h2><h3 id="4-1-1-local"><a href="#4-1-1-local" class="headerlink" title="4.1.1 local"></a>4.1.1 local</h3><p>本地模式，不需要安装 spark，也不需要启动 spark 集群。用于开发环境</p>
<h3 id="4-1-2-standalone"><a href="#4-1-2-standalone" class="headerlink" title="4.1.2 standalone"></a>4.1.2 standalone</h3><p>需要安装 Spark 需要启动 Spark 集群。<br><strong>client</strong>: driver 运行在和 sparksubmit 同一个进程中，此时如果关闭命令行窗口，相当于取消程序运行。可以从控制台看到程序输出内容<br><strong>cluster</strong>: driver 运行在 worker 节点上，spark-submit 提交后即退出，此时命令行窗口关闭，不影响程序运行，但是从控制台看不到程序输出内容。</p>
<h3 id="4-1-3-yarn"><a href="#4-1-3-yarn" class="headerlink" title="4.1.3 yarn"></a>4.1.3 yarn</h3><p>需要安装 spark，不需要启动 spark 集群。<br><strong>client</strong>: driver 运行在 client 进程中 ，此时如果关闭命令行窗口，相当于取消 程序运行。可以从控制台看到程序输出内容。<br><strong>cluster</strong>: driver 运行在 ApplicationMaster 进程 中，client 端提交后即退出，此时命令行窗口关闭，不影响程序运行，但是控制台上看不到程序输出内容</p>
<h3 id="4-1-4-mesos"><a href="#4-1-4-mesos" class="headerlink" title="4.1.4 mesos"></a>4.1.4 mesos</h3><h2 id="4-2-如何设置-Spark-配置属性"><a href="#4-2-如何设置-Spark-配置属性" class="headerlink" title="4.2 如何设置 Spark 配置属性"></a>4.2 如何设置 Spark 配置属性</h2><p>在 spark-defaults.conf 文件中设置 spark 的资源配置，资源分配参数名为 spark.xx.xx，如 spark.driver.cores</p>
<h3 id="4-2-1-有三种方式设置spark-的配置属性"><a href="#4-2-1-有三种方式设置spark-的配置属性" class="headerlink" title="4.2.1 有三种方式设置spark 的配置属性"></a>4.2.1 有三种方式设置spark 的配置属性</h3><p>（按优先级从高到低）</p>
<ol>
<li>在程序代码中通过 SparkConf 对象设置；</li>
<li>通过 spark-submit 任务提交参数设置；</li>
<li>通过 spark-defaults.conf 文件设置。</li>
</ol>
<h3 id="4-2-2-典型的-spark-defaults-conf-文件内容"><a href="#4-2-2-典型的-spark-defaults-conf-文件内容" class="headerlink" title="4.2.2 典型的 spark-defaults.conf 文件内容"></a>4.2.2 典型的 spark-defaults.conf 文件内容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark.executor.memory   8G</span><br><span class="line">spark.driver.memory 16G</span><br><span class="line">spark.driver.maxResultSize  8G</span><br><span class="line">spark.akka.frameSize    512</span><br></pre></td></tr></table></figure>

<h2 id="4-3-集群资源配置实战"><a href="#4-3-集群资源配置实战" class="headerlink" title="4.3 集群资源配置实战"></a>4.3 集群资源配置实战</h2><p>在 spark-env.sh 中配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_WORKER_CORES=1</span><br><span class="line">SPARK_WORKER_MEMORY=900m</span><br><span class="line">SPARK_WORKER_INSTANCES=2</span><br></pre></td></tr></table></figure>

<p><img src="/images/2019/07/24/8d693ad0-ae19-11e9-8908-0b6e2efa6f40.png" alt="sparkenv配置.png"></p>
<h2 id="4-4-Spark-应用程序-资源配置实战"><a href="#4-4-Spark-应用程序-资源配置实战" class="headerlink" title="4.4 Spark 应用程序 资源配置实战"></a>4.4 Spark 应用程序 资源配置实战</h2><h3 id="4-4-1-–executor-cores"><a href="#4-4-1-–executor-cores" class="headerlink" title="4.4.1 –executor-cores"></a>4.4.1 –executor-cores</h3><ol>
<li><blockquote>
<p>spark-submit –master spark://master01:7077 –executor-memory 900m –executor-cores 6 –class spark.learnTextFile /opt/sparkapp/learnTextFile.jar</p>
</blockquote>
</li>
</ol>
<p>上面的命令中，所需要的的单个 executor 的 cores 数量 6 超过了 worker 节点的 cores 数量（配置为单核），程序无法运行。<br><img src="/images/2019/07/24/db3c0530-ae19-11e9-8908-0b6e2efa6f40.png" alt="cores 配置超过物理节点 所有的核心数.png"></p>
<ol start="2">
<li>如果 worker 有足够的资源，对于同一个应用，会在一个 worker 上启动多个 executor。如：<blockquote>
<p>spark-submit –master spark://master01:7077 –executor-memory 918m –executor-cores 1 –class sparkcore.learnTextFile /opt/sparkapp/learnTextFile.jar</p>
</blockquote>
</li>
</ol>
<p><img src="/images/2019/07/24/e80555f0-ae19-11e9-8908-0b6e2efa6f40.png" alt="一个 worker 启动多 exe1.png"></p>
<p><img src="/images/2019/07/24/fb0fe890-ae19-11e9-8908-0b6e2efa6f40.png" alt="一个 worker 启动多 exe2.png"></p>
<p>另一个例子：</p>
<blockquote>
<p>spark-submit –master spark://master01:7077 –executor-memory 1200m –executor-cores 1 –class sparkcore.learnTextFile /opt/sparkapp/learnTextFile.jar<br><img src="/images/2019/07/24/008527e0-ae1a-11e9-8908-0b6e2efa6f40.png" alt="一个 worker 没启动多 exe1.png"></p>
</blockquote>
<p><img src="/images/2019/07/24/04841ae0-ae1a-11e9-8908-0b6e2efa6f40.png" alt="一个 worker 没启动多 exe2.png"></p>
<p>另一种参数赋值的方式：<br>–conf PROP=VALUE</p>
<blockquote>
<p>spark-submit –master spark://master01:7077 –conf spark.executor.memory-1201m –conf spark.executor.cores=1 –class sparkcore.learnTextFile /opt/sparkapp/learnTextFile.jar</p>
</blockquote>
<h3 id="4-4-2-参数优先级"><a href="#4-4-2-参数优先级" class="headerlink" title="4.4.2 参数优先级"></a>4.4.2 参数优先级</h3><p>spark.default.conf &lt; spark-submit -conf &lt; SparkConf 代码</p>
<p><strong>测试</strong>：</p>
<ol>
<li><p>代码：<br><img src="/images/2019/07/24/0deefe60-ae1a-11e9-8908-0b6e2efa6f40.png" alt="参数优先级 代码设置.png"></p>
</li>
<li><p>spark-submit:</p>
<blockquote>
<p>spark-submit –master spark://master01:7077 –conf spark.executor.memory=1201m  –conf spark.executor.cores=1 –class sparkcore.learnTextFile /opt/sparkapp/learnTextFile.jar</p>
</blockquote>
</li>
<li><p>运行结果：<br><img src="/images/2019/07/24/14ce5500-ae1a-11e9-8908-0b6e2efa6f40.png" alt="参数优先级 结果1.png"></p>
</li>
</ol>
<p><img src="/images/2019/07/24/19130390-ae1a-11e9-8908-0b6e2efa6f40.png" alt="参数优先级 结果2.png"></p>
<h3 id="4-4-3-几个常用的配置项"><a href="#4-4-3-几个常用的配置项" class="headerlink" title="4.4.3 几个常用的配置项"></a>4.4.3 几个常用的配置项</h3><p>Spark 常用配置项，主要是对 Spark  运行过程中各个使用资源的地方，通过调整参数值，来优化资源使用效率，提升 Spark 作业性能。以下每个参数都对应着 spark 应用程序运行原理中的某个部分，同时给出了一些参考值。</p>
<p><strong>1. num-executors</strong></p>
<ul>
<li><p><strong>参数说明</strong>：该参数用于<strong>设置 Spark 作业要用多少个 Executor 进程来执行</strong>。Driver 在向 YARN 集群管理器申请资源时，YARN 集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的 Executor 进程。默认只会给你启动少量的 Executor 进程，此时你的 Spark  作业的运行速度是非常慢的。</p>
</li>
<li><p><strong>参数调优建议</strong>：参考 yarn container 的大小，设置太少或太多的 Executor 进程都不好。设置的太少，无法充分利用集群资源；设置 的太多的话，大部分队列可能无法给予充分的资源。</p>
</li>
</ul>
<p><strong>2. executor-memory (spark.executor.memory)</strong></p>
<ul>
<li><p><strong>参数说明</strong>：该参数用于设置每个 Executor 进程的内存 。Executor 内存的大小，很多时候直接决定了 Spark 作业的性能，而且跟常见的 JVM OOM异常，也有直接的关联。Executor 8G 4Core; 2Executor 4G 2Core</p>
</li>
<li><p><strong>参数调优建议</strong>：每个 Executor 进程的内存设置 4G ~ 8G 较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors 乘以 executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源 队列最大总内存的 1/3~1/2，避免你自己的 Spark 作业占用了队列所有的资源，导致别的作业无法运行。</p>
</li>
</ul>
<p><strong>3. executor-cores (spark.executor.cores)</strong></p>
<ul>
<li><strong>参数说明</strong>：该参数用于设置每个 Executor 进程的 CPU core数量。这个参数决定了每个 Executor 进程并行执行 task 线程的能力。因为每个 CPU core 同一时间只能执行一个 task 线程，因此每个 Executor 进程的 CPU core 数量越多，越能够快速地执行完分配给自己的所有 task 线程。</li>
<li><strong>参数调优建议</strong>：Executor 的 CPU core 数量设置为2 ~ 3 个较为合适。同样地根据不同部门的资源队列来定，可以看看自己的资源队列的最大 CPU core限制是多少，再依据设置的 Executor 数量，来决定每个 Executor 进程可以分配到几个 CPU core。同样建议，如果是跟他人共享这个队列，那么 num-executors * executor-cores 不要超过队列总 CPU core 的1/3~1/2 左右比较合适，也是避免影响其他同学的作业运行。</li>
</ul>
<p><strong>4. driver-memory</strong></p>
<ul>
<li><strong>参数说明</strong>：该参数用于设置 Driver 进程的内存。</li>
<li><strong>参数调优建议</strong>：Driver 的内存通常来说不设置，或者设置 1G 左右应该就够了。唯一需要注意的一点是，如果需要使用 <strong>collect 算子</strong>将RDD的数据全部拉取到 Driver 上进行处理，那么必须确保 Driver 的内存足够大，  否则会出现 OOM 内存溢出的问题。</li>
</ul>
<p><strong>5. spark.default.parallelism</strong></p>
<ul>
<li><strong>参数说明</strong>：该参数用于设置每个 stage 的默认 task 数量。这个参数极为重要，如果不设置可能会直接影响你的 Spark 作业性能。</li>
<li><strong>参数调优建议</strong>：Spark 作业的默认 task  数量为 500 ~ 1000 个较为合适。如果不设置这个参数，那么此时就会导致 Spark 自己根据底层 HDFS的 block数量来设置 task的数量，默认是一个 HDFS block 对应一个 task。通常来说，Spark 默认设置的数量是偏少的，如果task 数量偏少的话，就会导致你前面设置好的 Executor 的参数都无法提升性能。比如，无论你的 Executor 内存和 CPU 有多大，但是  task 只有一个或者几个，那么 90% 的 Executor 进程可能根本就没有 task  执行，也就是白白浪费了资源！因此 Spark 官网建议的设置原则是，<strong>设置该参数为 num-executors * executor-cores 的 2~3 倍比较合适</strong>。</li>
</ul>
<p><strong>5. spark.storage.memoryFraction</strong></p>
<ul>
<li><p><strong>参数说明</strong>：该参数用于设置 RDD 持久化数据在 Executor 内存中能占的比例，默认是 0.6。也就是说，默认 Executor 60% 的内存，可以用来保存持久化的 RDD数据。</p>
</li>
<li><p><strong>参数调优建议</strong>：如果 Spark 作业中，有较多的 RDD 持久化操作，该参数的值可以适当 提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果 Spark 作业中的 shuffle 类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的 gc 导致运行缓慢 （通过 spark web ui 可以观察到作业的 gc 耗时），意味着 task 执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>
</li>
</ul>
<p><strong>6. spark.shuffle.memoryFraction</strong></p>
<ul>
<li><strong>参数说明</strong>：该参数用于设置 shuffle 过程中一个 task 拉取到上个 stage 的task 的输出后，进行聚合操作时能够使用的 Executor 内存的比例，默认是 0.2。也就是说，Executor 默认只有 20% 的内存用来进行该操作。shuffle 操作在进行聚合时，如果发现使用的内存超过了这个 20% 的内存用来进行该操作。shuffle 操作在进行聚合时，如果发现使用的内存超过了这个 20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</li>
<li><strong>参数调优建议</strong>：如果 Spark 作业中的 RDD 持久化操作较少，shuffle 操作较多时，建议降低持久化操作的内存占比，提高 shuffle 操作的内存占比比例，避免 shuffle 过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现由于频繁的 gc 导致运行缓慢，意味着 task 执行用户代码的内存不够用，那么同样建议调低这个参数值。</li>
</ul>
<p><strong>注</strong>：资源参数的调优，没有一个固定的值，需要根据自己的实际情况（包括 Spark 作业中的 shuffle 操作数量、RDD 持久化操作数量以及 spark web UI 中显示的作业 gc 情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。</p>
<h1 id="5-Spark-on-yarn"><a href="#5-Spark-on-yarn" class="headerlink" title="5. Spark on yarn"></a>5. Spark on yarn</h1><h2 id="5-1-概述"><a href="#5-1-概述" class="headerlink" title="5.1 概述"></a>5.1 概述</h2><ol>
<li><p>Spark 支持可插拔的集群管理器（Standalone, YARN），集群管理负责启动 executor 进程。Spark  支持的四种集群模式（standalone, mesos, yarn, Kubernetes），三种集群模式都是由两个组件组成：master 和 slave。Master 服务（YARN ResourceManager, Mesos master 和 Spark standalone master）决定哪些 application 可以运行，何时运行以及在哪里运行。而 slave 服务（YARN NodeManager, Mesos slave 和 Spark standalone worker）是运行 executor 进程。</p>
</li>
<li><p>当在 YARN 上运行 Spark 作业，每个 Spark executor 作为一个 YARN 容器（container）运行。Spark 应用程序的多个 Tasks 在同一个容器（container）里面运行。注意：MapReduce作业为每个 Task 开启不同的 JVM 来运行。</p>
</li>
<li><p>不需要启动 spark 集群，但是需要配置 SPARK_HOME。<br>配置 HADOOP_CONF_DIR=$HADOOP_HOME。</p>
</li>
<li><p>提交命令：</p>
<blockquote>
<p>spark-submit –class sparkcore.learnTextFile –master yarn –deploy cluster /opt/sparkapp/learnTextFile.jar</p>
</blockquote>
</li>
<li><p>查看输出：</p>
<blockquote>
<p>yarn logs –applicationId application_xxx</p>
</blockquote>
</li>
<li><p>查看任务运行状态：</p>
<blockquote>
<p>yarn application -status application_xx</p>
</blockquote>
</li>
</ol>
<h2 id="5-2-资源分配"><a href="#5-2-资源分配" class="headerlink" title="5.2 资源分配"></a>5.2 资源分配</h2><p>资源分配包括内存的分配和 CPU 的分配</p>
<h3 id="5-2-1-CPU-的分配"><a href="#5-2-1-CPU-的分配" class="headerlink" title="5.2.1 CPU 的分配"></a>5.2.1 CPU 的分配</h3><p>Spark 计算的关键抽象是 RDD，RDD 包括多个 partitions, 一个 partition 对应一个 task，对应一个 CPU core。一个 spark job 的并行度依赖于 RDD的partitions 和可用的 CPU cores。</p>
<h3 id="5-2-2-内存的分配"><a href="#5-2-2-内存的分配" class="headerlink" title="5.2.2 内存的分配"></a>5.2.2 内存的分配</h3><p><strong>spark 内存主要用于执行 job（执行内存）和存储数据（存储内存）</strong>。<br>执行内存可以驱逐存储内存（仅在存储内存达到一定阈值时）。存储内存不可以驱逐执行内存。</p>
<p><strong>执行内存</strong>用于 shuffle、joins、sorts 和 aggregations。</p>
<p><strong>存储内存</strong>用于缓存数据和集群内传播数据。</p>
<h2 id="5-3-如何给-Spark-分配资源"><a href="#5-3-如何给-Spark-分配资源" class="headerlink" title="5.3 如何给 Spark 分配资源"></a>5.3 如何给 Spark 分配资源</h2><p><strong>1.</strong> 当 Spark 应用运行在 yarn 上面，对 yarn 来说，Spark 应用只是一个应用，就像 MapReduce 应用一样，只是一个运行在 yarn 上面的应用而已。这是极好的！因为你已经学得有关 yarn 架构、资源分配和调优知识，对 Spark on yarn 完全有效。</p>
<p><strong>2.</strong> 如前所述，yarn 有两个关键的实体：<br><strong>ResourceManager</strong>–管理集群资源；<br><strong>ApplicationMaster</strong>–负责从 ResourceManager 请求资源，进而将资源分配给每个集群节点上的 <strong>NodeManager</strong>，这样集群就可以执行每个 task。</p>
<p><strong>3.</strong> ApplicationMaster 是属于某个特定 Application的，执行 MapReduce 应用时，yarn 使用了 MapReduce 框架特定的 ApplicationMaster，当执行 Spark job 时，yarn 使用了 Spark 框架特定的 ApplicationMaster。</p>
<p><strong>4.</strong> yarn 通过逻辑抽象单元 container 来分配资源，container 代表一个资源集——内存和 CPU。例如，一个 container 可以由 2个 CPU core 和 4G 内存组成。当 Spark ApplicationMaster 从 ResourceManager 请求资源时，通过评估 job 的资源需求，然后请求一定数量的 container 来完成 job。基于集群可用资源，ApplicationMaster 会要求 worker 节点上的 NodeManaer 运行一定数量的 container。</p>
<p><strong>5.</strong> 当运行 Spark on yarn 应用时，Spark 位于 yarn 架构之上，使用相同的过程请求资源，yarn 用相同的方式将 container 分配给 Spark job。Spark 所有的 executor 和 driver 都运行在 container 中，ApplicationMaster 负责 container 间的通信。</p>
<p><strong>6.</strong> ApplicationMaster 运行在一个单独的 container 中。Executor 也运行在 yarn container 中，一个 Executor 运行在一个 container 中，在 MapReduce 应用资源分配过程中，一个 map/reduce task 运行在单独的 container 中。但是，在 spark Executor 中，Executor container 包含一个更细粒度的实体——task。每个 Executor container 可以运行一个 task 集合，来完成实际的工作。</p>
<p><strong>7.</strong> Spark 使用了由 YARN 管理的两个关键资源：CPU 和内存。虽然磁盘 I/O 和网络性能对应用程序性能有影响，YARN 并不是真正关注这些资源。</p>
<h2 id="5-4-Spark-应用资源分配的限制"><a href="#5-4-Spark-应用资源分配的限制" class="headerlink" title="5.4 Spark 应用资源分配的限制"></a>5.4 Spark 应用资源分配的限制</h2><p>可以配置 YARN 属性来限制 YARN 可以使用的最大内存和 CPU core。Spark 的资源使用受限于这些配置属性。总结一下这些属性。</p>
<ul>
<li><p><strong>yarn.nodemanager.resource.memory-mb</strong> 参数设置了分配给集群中一个运行 NodeManager 节点 上所有 container 的内存上限。此内存设置对 Spark on yarn 同样有效。</p>
</li>
<li><p><strong>yarn.nodemanager.resource.cpu-vcores</strong> 参数设置了集群中一个运行 NodeManager 节点上所有 containers 可以使用的最大 CPU 核心数。</p>
</li>
</ul>
<ol>
<li><p>yarn 以块的形式分配内存，内存块的大小依赖于参数 yarn.scheduler.minimum-allocation-mb 值—— yarn 可以为每个 container 请求分配的最小内存块。</p>
</li>
<li><p>yarn 以 core 的形式分配 CPU，core 的个数依赖于参数 yarn.scheduler.minimum-allocation-vcores 值—— yarn 可以为每个 container 请求分配的最小 core 数。</p>
</li>
</ol>
<h2 id="5-5-spark-on-yarn-应用的提交方式"><a href="#5-5-spark-on-yarn-应用的提交方式" class="headerlink" title="5.5 spark on yarn 应用的提交方式"></a>5.5 spark on yarn 应用的提交方式</h2><ol>
<li><p>yarn-client 模式：spark driver 运行在客户端 client 进程中。YARN ApplicationMaster 进程代表应用向 YARN 请求资源；<br>client 向 yarn 的 RM 申请 container，用于运行 AM，RM 在 NodeManager 上启动 container 运行 AM （里面没有 SparkContext），SparkContext 在 client 端实例化，会通知 AM，申请资源，AM 向 RM 申请资源，AM 在 NodeManager 上启动 container(executor), SparkContext 分配 task 给 executor，executor 启动线程池执行，运行完成后，driver 会通知 RM 收回资源，sparkcontext.close()。</p>
</li>
<li><p>yarn-cluster 模式：spark driver 运行在 YARN 管理的 ApplicationMaster 进程中——client 将定期轮询 AM 以获取状态更新，并在控制台显示它们。一旦应用程序运行完毕，client 将退出。</p>
<br>
client 向 yarn 的 RM 申请 container，用于运行 AM，RM 在 NodeManager 上启动 container 运行 AM，**AM 类里面会实例化 SparkContext(driver)**，AM 向 RM 申请资源，AM 在 NodeManager 上启动 container(executor), sparkContext 分配 task 给 executor，executor 启动线程池执行，运行完成后，driver 会通知 RM 收回资源，sparkcontext.close()。

</li>
</ol>
<h2 id="5-6-Spark-on-yarn-的资源分配依赖于-spark-的运行模式"><a href="#5-6-Spark-on-yarn-的资源分配依赖于-spark-的运行模式" class="headerlink" title="5.6 Spark on yarn 的资源分配依赖于 spark 的运行模式"></a>5.6 Spark on yarn 的资源分配依赖于 spark 的运行模式</h2><p>因此，我们分别讨论 client 和 cluster 模式中的资源分配。</p>
<p>注意，关于配置 YARN 资源分配的所有知识，为 Spark 分配资源仍然有效。</p>
<p><strong>yarn 需要为以下 Spark 关键实体分配资源</strong>：</p>
<ol>
<li>driver</li>
<li>Executor</li>
</ol>
<h3 id="5-6-1-为-spark-driver-分配资源"><a href="#5-6-1-为-spark-driver-分配资源" class="headerlink" title="5.6.1 为 spark driver 分配资源"></a>5.6.1 为 spark driver 分配资源</h3><p>在开始讨论如何分配资源给 Spark driver 之前，请允许我总结一下 driver 所扮演的角色。</p>
<p><strong>driver 的职责</strong><br>spark on yarn 应用程序的 driver 进程完成如下功能：</p>
<ol>
<li>使用 spark 执行引擎，将应用程序分成 job，stages 和 tasks。</li>
<li>为 Executor 进程提供包依赖服务。 –jars</li>
<li>与 YARN ResourceManager 交互，获取资源，分配给各个节点用于执行应用程序的 task。</li>
</ol>
<p><strong>注意</strong>：</p>
<ul>
<li>在 Spark 运行环境中，driver负责：</li>
</ul>
<ol>
<li>定义和调用 RDD 的 action；</li>
<li>跟踪 RDD 的血统 lineage。</li>
</ol>
<ul>
<li>workers(executors)负责：</li>
</ul>
<ol>
<li>存储 RDD partitions;</li>
<li>执行 RDD transformation。</li>
</ol>
<p>一旦 driver 获取资源执行 Spark Application, 其会创建一个执行计划——根据应用程序代码中的 action 和 transformation 生成一个有向无环图 DAG，并发送给 worker节点。</p>
<p>driver 进程包括两个组件，用来处理 task 分配：</p>
<ol>
<li>DAG Scheduler 进程将 DAG 划分为 task；</li>
<li>task scheduler 在集群各个节点间调度 task。一旦 task scheduler 完成了 task 分配，Executor 开始执行 DAG 中的操作。如果有 task 失败或者出现延迟，task scheduler 会重启失败（失败次数可配置 4 次）的 task 或创建新的 task 来替换延迟的 task。</li>
</ol>
<h2 id="5-7-Client-模式下-AM、Driver-的资源分配"><a href="#5-7-Client-模式下-AM、Driver-的资源分配" class="headerlink" title="5.7 Client 模式下 AM、Driver 的资源分配"></a>5.7 Client 模式下 AM、Driver 的资源分配</h2><p>Spark on yarn cient 模式，Spark 应用程序对应的 AM 的资源分配依赖于下面两个配置参数：</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数描述</th>
<th>默认值</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>spark.yarn.am.memory</td>
<td>AM 的 JVM 堆内存</td>
<td>512M</td>
<td>spark.yarn.am.memory 777m</td>
</tr>
<tr>
<td>spark.yarn.am.cores</td>
<td>AM 可用的 core 数量</td>
<td>1</td>
<td>spark.yarn.am.cores 4</td>
</tr>
</tbody></table>
<p>由于 YARN 分配资源的单位是 container，那么 AM 运行所在的 container 的大小是多少呢？使用参数spark.yarn.am.memory 设置的内存并不意味着 yarn 为 container 分配的内存就是 777m。</p>
<p>在 client 模式下，Spark 为 AM 进程分配了一定量的堆外内存。配置参数 spark.yarn.am.memoryOverhead 设置了堆外内存的大小。默认值为：<br><strong>AM Memory * 0.1，最小值为 384M</strong></p>
<p>那么，我们为 AM 设置了 777MB，777MB*0.1 = 77.7MB，比 384MB 小，所以堆外内存为 384MB。AM 的 cotainer 大小为 777MB+384MB=1161MB，因为 yarn.scheduler.minimum-allocation-mb 的默认值为 1G，yarn 会做舍入操作，为 AM 分配一个内存为 2G 的 container。所以，上例中的 container 大小为：2GB 内存（java 堆内存：-Xmx777M）和 4 CPU core。</p>
<p>Client 模式下的 driver 内存，使用 spark.driver.memeory</p>
<h2 id="5-8-Cluster-模式下-AM、Driver-的资源分配"><a href="#5-8-Cluster-模式下-AM、Driver-的资源分配" class="headerlink" title="5.8 Cluster 模式下 AM、Driver 的资源分配"></a>5.8 Cluster 模式下 AM、Driver 的资源分配</h2><p>在 cluster 模式下，spark driver 运行在 yarn ApplicationMaster 进程中。所以，分配给 AM 的资源决定了 driver 的可用资源。下面看下 driver 相关的资源配置参数，这些配置参数，控制了 ApplicationMaster 的资源分配。</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数描述</th>
<th>默认值</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>spark.drivers.cores</td>
<td>AM 可用的 core 数量</td>
<td>1</td>
<td>spark.driver.cores 2</td>
</tr>
<tr>
<td>spark.driver.memory</td>
<td>AM 的 JVM 堆内存</td>
<td>512M</td>
<td>spark.driver.memory 1665m</td>
</tr>
<tr>
<td>spark.driver.memoryOverhead</td>
<td>Driver 堆外内存</td>
<td>driverMemory * 0.1，至少 384M</td>
<td></td>
</tr>
</tbody></table>
<p><strong>注意</strong>：与 client 模式一样，cluster 模式也有一个类似的配置参数：<br>spark.driver.memoryOverhead 用于指定 cluster模式下的堆外存大小。该属性默认值为分配给 ApplicationMaster 内存的 10%，最小值为 384M。</p>
<p><strong>提示</strong>：在 cluster 模式中，当你配置 spark driver 的资源时，间接配置了 yarn AM 服务的资源，因为 driver 运行在 AM 中。</p>
<p>因为 1665+Max(384, 1665*0.1) = 1665+384 = 2049 &gt; 2048，并且 yarn.scheduler.minimum-allocation-mb = 1024，所以 container 大小为：3GB 内存（Java 堆内存：-Xmx1665M）和 2 CPU core。</p>
<h2 id="5-9-Executor-的资源配置"><a href="#5-9-Executor-的资源配置" class="headerlink" title="5.9 Executor 的资源配置"></a>5.9 Executor 的资源配置</h2><p>Spark 任务的真正执行是在 worker 节点上——也就是说所有的 task 运行在 worker 节点上。<strong>spark job 的大部分资源应该分配给 Executor</strong>。相比而言，driver 的资源分配要小的多。</p>
<p><strong>对于 Spark executor 资源，yarn-client 和 yarn-cluster 模式使用相同的配置</strong>。</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数描述</th>
<th>默认值</th>
</tr>
</thead>
<tbody><tr>
<td>spark.executor.instances(–num-executors)</td>
<td>用于静态分配 executor 的数量</td>
<td>2</td>
</tr>
<tr>
<td>spark.executor.cores(–executor-cores)</td>
<td>单个 executor 的 core 数量</td>
<td>1</td>
</tr>
<tr>
<td>spark.executor.memeory(–executor-memeory)</td>
<td>每个 executor 的堆内存大小</td>
<td>1G</td>
</tr>
<tr>
<td>spark.executor.memoryOverhead</td>
<td>每个 executor 的堆外存大小</td>
<td>executorMemory*0.1，至少 384M</td>
</tr>
</tbody></table>
<p><strong>计算：如果设置 spark.executor.memeory 大小为 2G，那么将启动 2 个 container，大小为 3G，1core，-Xmx2048M</strong></p>
<p>在 Spark 资源分配表述中，Executor 是 container 的同义词——即一个 Executor，一个 Container。因此，Spark 的 Executor 的分配转换成了 yarn 的 container 的分配。当 Spark 计算出所需要的 Executor 数量，其与 AM 交互，AM 进而与 YARN RM 交互，请求分配 container。</p>
<p>spark.executor.memeory 参数设置会影响下面两个地方：<br>–Spark 可以缓存的数据量；<br>–shuffle 操作可以使用的内存最大值。</p>
<p>下图展示了 spark executor 内存与 yarn 总内存 yarn.nodemanager.resource.memory-mb的关系：<br><img src="/images/2019/07/25/81920210-aea4-11e9-8908-0b6e2efa6f40.png" alt="图展示了.png"></p>
<p>下面的例子显示了在提交 Spark 应用程序时，如何设置目前为止讨论的属性：</p>
<blockquote>
<p>spark-submit –class org.apaches.spark.example.SparkPi \<br>–master yarn \<br>–deploy-mode cluster \<br>–driver-memory 4g \<br>–executor-memory 2g \<br>–executor-cores 1 \<br>–queue thequeue \<br>lib/spark-example*.jar \<br>10</p>
</blockquote>
<h2 id="5-10-Spark-内存使用"><a href="#5-10-Spark-内存使用" class="headerlink" title="5.10 Spark 内存使用"></a>5.10 Spark 内存使用</h2><h3 id="5-10-1-Spark-如何使用内存"><a href="#5-10-1-Spark-如何使用内存" class="headerlink" title="5.10.1 Spark 如何使用内存"></a>5.10.1 Spark 如何使用内存</h3><p>在前面的章节中，我解释了如何分配内存给 Spark：通过分配内存给 driver 和 executor。Spark 是如何使用分配到的内存呢？Spark 主要在两个方面使用内存：执行代码和存储数据（执行内存 execute memory 和存储内存 storage memory）。<br><strong>执行内存</strong>，用于执行 Spark 操作，包括 shuffle, joins 和 sorts。<br><strong>存储内存</strong>，用于 Spark 缓存数据和在集群间移动中间数据。<br>执行内存的增加，会导致内存中的数据对象被清除，直到存储内存值达到一个阈值。</p>
<h3 id="5-10-2-Spark-内存使用的配置"><a href="#5-10-2-Spark-内存使用的配置" class="headerlink" title="5.10.2 Spark 内存使用的配置"></a>5.10.2 Spark 内存使用的配置</h3><p>为了了解 Spark 如何分配执行内存和存储内存，我会用下列符号代表内存的各个组成部分。</p>
<ul>
<li><strong>M</strong>：表示执行内存和存储内存的总和。</li>
<li><strong>R</strong>：最小存储空间（阈值），低于这个值，不能将 RDD 从存储内存中清除出去。</li>
</ul>
<p>使用以下两个配置属性来调整执行内存和存储内存大小：</p>
<ul>
<li><p><strong>spark.memory.fraction</strong>：这个分数表示 M 是 JVM 堆空间的一部分。默认值为0.75（Spark1.6），0.6（Spark2.0）。意思是：分配给 executor 的内存，60% 用于 M，剩下的 40% 用于存储用户数据结构和内部 Spark 元数据。Apache Spark 建议保留该属性默认值。</p>
</li>
<li><p><strong>spark.memory.storageFraction</strong>：这个分数表示，保留存储内存 R 的大小占总内存 M 的百分比。默认值为 0.5。意思是：如果 Spark 应用程序缓存的 RDD 位于 M 总内存的 50% 之内，将禁止被清除出去。注意：这个属性值越大，用于执行代码的内存越小，task 会频繁溢出数据到磁盘。Apache Spark 建议保留该属性默认值。如果在执行 Spark 应用程序过程中，频繁发生 GC，此时可以适当调低这个属性值，如从 0.5 调低到 0.4，这样 M 中的 60% 内存用于代码执行。如：</p>
<blockquote>
<p>spark-shell –conf spark.memory.storageFraction=0.4</p>
</blockquote>
</li>
</ul>
<h3 id="5-10-3-一个-Executor-究竟能使用多少内存？"><a href="#5-10-3-一个-Executor-究竟能使用多少内存？" class="headerlink" title="5.10.3 一个 Executor 究竟能使用多少内存？"></a>5.10.3 一个 Executor 究竟能使用多少内存？</h3><p>分配给 Executor 的内存是 Spark 应用程序执行的关键。假设你设置了 spark.executor.memory 的值为 4GB，那么 4GB内存中，有多少内存真正用于 Spark 应用程序代码执行呢？下面的分析显示了 executor 实际上可以使用多少内存执行代码。</p>
<ol>
<li><p>首先，Spark 会从 4GB Java heap 中减去 300MB，作为”reserved memeory”（保留内存）。现在 Java heap 中只剩下 4096-300= 3796MB 内存。</p>
</li>
<li><p>spark.memory.fraction 属性值，按默认值 0.75，将会使用内存 0.75*3796=2847MB。</p>
</li>
<li><p>spark.memory.storageFraction 属性值，默认值 0.5，那么用于存储内存的大小为：0.5*2847MB=1423.5MB，这是初始存储内存区域大小。</p>
</li>
<li><p>executor 可以使用另外的 50%，即 1423.5MB 执行应用程序代码。</p>
</li>
</ol>
<p>好好看看你的的应用程序并为存储内存和执行内存找出近似比例。然后调整 spark.memory.fraction 和 spark.memory.storageFraction 的属性值。Spark 建议您保留默认位置，因为它们是用于大多数应用程序场景。但是，每个 Spark 应用程序都是不同的。</p>
<h3 id="5-10-4-发现当前内存使用量"><a href="#5-10-4-发现当前内存使用量" class="headerlink" title="5.10.4 发现当前内存使用量"></a>5.10.4 发现当前内存使用量</h3><p>如果您想要计算 RDD 需要多少内存，最好的办法是创建 RDD 并缓存它。然后您可以查看 Spark web UI 存储页面统计数据，以计算 RDD 的当前内存使用量。</p>
<p>使用 SizeEstimator 类的 estimate 方法计算某个对象占内存空间的大小。具体用法参见：<br><a href="https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/util/SizeEstimator.html" target="_blank" rel="noopener">https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/util/SizeEstimator.html</a><br>您可以尝试各种存储、执行内存设置来优化内存使用。</p>
<h3 id="5-10-5-需要记住的几点"><a href="#5-10-5-需要记住的几点" class="headerlink" title="5.10.5 需要记住的几点"></a>5.10.5 需要记住的几点</h3><p>以下是您在配置用于 Sparkdriver 程序和 Executor 的资源时可能需要考虑的一些重要事项。</p>
<p><strong>1. 使用尝试和错误来调整 executor 内存</strong><br>如果分配给 Executor 过多的内存，GC 会耗时较长。然而，在许多情况线下，您需要为 Executor 分配更高的内存，因为默认值只有 1024MB。在一个特定应用程序调优中，你可以尝试升高不同的内存值，以找到合适的数字。大多数情况下，分配给 Executor 的内存不需要超过 6GB，大约 4GB 的大小对于一个 Executor 来说是一个很好的内存分配。任何分配内存太多，垃圾回收可能会对应用程序性能产生负面影响，尽管如果使用新的 GC 方法（G1GC），可以减轻这种情况。</p>
<p><strong>2. 限制每个 Executor 的 task 数量</strong></p>
<h2 id="5-11-Client-模式还是-Cluster-模式"><a href="#5-11-Client-模式还是-Cluster-模式" class="headerlink" title="5.11 Client 模式还是 Cluster 模式"></a>5.11 Client 模式还是 Cluster 模式</h2><p>在client 模式下，spark-submit 脚本创建了 driver，driver 与任务提交脚本运行在同一个进程中，此时，你可以方便的跟踪调试应用程序，因为应用程序的输出信息都会打印到屏幕上。如果在你的笔记本电脑上面运行 spark-submit 命令提交应用程序，然后关闭了笔记本电脑，那么这个应用程序就死掉；如果是在 cluster 模式下，这种情况不会影响应用程序的执行，因为你提交应用程序后，应用程序 driver 会在集群节点上运行。在 cluster 模式下，ResourceManager 决定 driver 进程运行在哪个集群节点上，不能人为指定。因此，需要保证在所有的集群节点上提供了所有的依赖库，如 jar 文件和 py 文件等。</p>
<p><strong>spark.driver.maxResultSize</strong> 配置参数决定了 spark action 操作中，RDD 所有分区的记录总数大小，如 collect()。默认值为 1GB，如果数据集过大，你需要调高此参数值，因为一旦超过了此参数值，job 会被 kill 掉。如果你调高了这个参数值，请确认同时调高 <strong>spark.driver.memory</strong>参数值。<strong>spark.driver.maxResultSize</strong> 参数值为 0，无限大。</p>
<p><strong>spark.cleaner.ttl</strong> 参数，定时清理 spark 程序运行过程中产生的元数据（stages 元数据或 task 元数据），对于长时间运行的 Spark Streaming 程序可以设置这个参数，以避免耗尽 driver 内存。</p>
<p><strong>配置 spark 相关的网络参数</strong><br>spark 使用 akka 框架进行网络通信。在生产环境中，有两个重要的网络配置参数可能需要调整：</p>
<ol>
<li><p><strong>spark.akka.framesize</strong>: 默认值为128MB，设置了 driver 和 executors 传输消息的最大值。如果 job 运行了大量的 map/reduce task，可能需要调整这个参数。</p>
</li>
<li><p><strong>spark.akka.threads</strong>：默认值为 4，设置了用于交互的 akka actor 线程数。如果 driver 配置了多个 cpu core，你可能需要提升这个参数值。</p>
</li>
</ol>

    
  </div>

</article>


   
  <div class="text-center donation">
    <div class="inner-donation">
      <span class="btn-donation">支持一下</span>
      <div class="donation-body">
        <div class="tip text-center">扫一扫，支持forsigner</div>
        <ul>
        
          <li class="item">
            
              <span>微信扫一扫</span>
            
            <img src="/images/qr-wechat.png" alt="">
          </li>
        
          <li class="item">
            
              <span>支付宝扫一扫</span>
            
            <img src="/images/qr-alipay.png" alt="">
          </li>
        
        </ul>
      </div>
    </div>
  </div>


   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2019/07/24/Spark-编程核心抽象——RDD/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2019/08/02/Spark-调优/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>




</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/atom.xml"
              rel="noopener noreferrer"
              target="_blank"
              >
              RSS
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    

    
    

    

    
    

    

<!-- Gitalk评论插件通用代码 -->
<div id="gitalk-container"></div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script>
const gitalk = new Gitalk({
  clientID: 'cffabda338955fb33e72',
  clientSecret: '27685d32607acc9c76041016860f5434fa1d65d0',
  repo: 'gitalk_comment',
  owner: 'Miracle-Xing',
  // 在这里设置一下截取前50个字符串, 这是因为 github 对 label 的长度有了要求, 如果超过
  // 50个字符串则会报错.
  // id: location.pathname.split('/').pop().substring(0, 49),
  id: location.pathname,
  admin: ['Miracle-Xing'],
  // facebook-like distraction free mode
  distractionFreeMode: false
})
gitalk.render('gitalk-container')
</script>
<!-- Gitalk代码结束 -->



  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
