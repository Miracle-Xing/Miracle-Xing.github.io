<!DOCTYPE html>


  <html class="light page-post">


<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>Spark 概念及应用程序架构 | 邢大强的blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Spark,">
  

  <meta name="description" content="概念 Spark是计算框架，不是存储框架。类似Hadoop中的MR  Spark是分布式的内存计算框架，Spark在计算的时候，内存不够用，数据会写到磁盘。">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark 概念及应用程序架构">
<meta property="og:url" content="https://miracle-xing.github.io/2019/07/22/Spark-概念及应用程序架构/index.html">
<meta property="og:site_name" content="邢大强的blog">
<meta property="og:description" content="概念 Spark是计算框架，不是存储框架。类似Hadoop中的MR  Spark是分布式的内存计算框架，Spark在计算的时候，内存不够用，数据会写到磁盘。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://miracle-xing.github.io/images/2019/07/22/42616bf0-abd7-11e9-87f2-3dee39091945.png">
<meta property="og:updated_time" content="2019-08-29T18:41:52.688Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark 概念及应用程序架构">
<meta name="twitter:description" content="概念 Spark是计算框架，不是存储框架。类似Hadoop中的MR  Spark是分布式的内存计算框架，Spark在计算的时候，内存不够用，数据会写到磁盘。">
<meta name="twitter:image" content="https://miracle-xing.github.io/images/2019/07/22/42616bf0-abd7-11e9-87f2-3dee39091945.png">

  

  
    <link rel="icon" href="/assets/img/m.png">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    <link rel="stylesheet" href="/css/personal-style.css">
  

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-38189205-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?57e94d016e201fba3603a8a2b0263af0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>
</html>
<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">盒子</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/atom.xml"
            rel="noopener noreferrer"
            target="_blank"
            >
            RSS
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#概念"><span class="toc-text">概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark-应用程序架构"><span class="toc-text">Spark 应用程序架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Spark-Driver"><span class="toc-text">1.  Spark Driver</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-SparkContext"><span class="toc-text">1.1 SparkContext</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-应用程序执行计划"><span class="toc-text">1.2 应用程序执行计划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-应用程序的调度"><span class="toc-text">1.3 应用程序的调度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-其他功能"><span class="toc-text">1.4 其他功能</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Executor-和-worker"><span class="toc-text">2. Executor 和 worker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Master-和-Cluster-Manager"><span class="toc-text">3. Master 和 Cluster Manager</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Master"><span class="toc-text">3.1 Master</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Cluster-Manager（集群管理器）"><span class="toc-text">3.2 Cluster Manager（集群管理器）</span></a></li></ol></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-Spark-概念及应用程序架构" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">Spark 概念及应用程序架构</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.07.22</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>Miracle</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/笔记/">笔记</a>
  </span>



      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><ol>
<li><p>Spark是计算框架，不是存储框架。类似Hadoop中的MR</p>
</li>
<li><p>Spark是分布式的内存计算框架，Spark在计算的时候，内存不够用，数据会写到磁盘。</p>
<a id="more"></a>
</li>
<li><p>Spark和Hadoop没有必然联系，两者是独立的。</p>
</li>
<li><p>Spark可以读取HDFS / fileSystem / DB / Kafka / Flume上的数据，可以把数据写到HDFS / fileSystem / DB / Kafka / Flume中。</p>
</li>
<li><p>Spark可以使用YARN做资源调度管理器 Spark on YARN。</p>
</li>
<li><p><strong>数据不动代码动</strong>。</p>
</li>
<li><p>Spark架构：Master Slave架构，主从架构，一主多从。</p>
</li>
<li><p>主从架构的突出问题是 <strong>单点故障</strong>，HA（高可用）架构就是为了解决单点故障，心跳消息。</p>
</li>
<li><p>主主架构：Flume，Kafka</p>
</li>
<li><p>数据本地性：计算时从最近的节点读取数据。</p>
</li>
<li><p>粗粒度、细粒度<br>指的是资源分配方式。<br>粗粒度：应用启动，资源就分配给你，你用不用都是你的。<br>细粒度：不提前分配资源，你需要的时候再给你。</p>
</li>
<li><p>Spark两种算子 <strong>Transformation</strong> 和 <strong>Action</strong><br>Transformation算子返回值是 RDD，Action算子返回值是计算结果，不是RDD。</p>
</li>
<li><p>Spark 有四种部署方式：Standalone / Spark on YARN / Apache Mesos / Kubernetes</p>
</li>
<li><p>Spark Shell 是Spark提供的本地交互式脚本，默认启动时Local模式，使用Scala语言。</p>
</li>
</ol>
<p><strong>Scala 一行代码实现 wordcount</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">textFile.flatMap(line=&gt;line.split(&quot; &quot;)).map(word=&gt;(word,1)).reduceByKey(_+_).sortBy(_._2,false).collect().foreach(println)</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Spark-应用程序架构"><a href="#Spark-应用程序架构" class="headerlink" title="Spark 应用程序架构"></a>Spark 应用程序架构</h1><ol>
<li><p>Spark 应用程序组件：driver, the master, the cluster manager 和运行在worker节点的executor(s)<br><img src="/images/2019/07/22/42616bf0-abd7-11e9-87f2-3dee39091945.png" alt="Spark 应用程序架构.png"><br>所有Spark组件，包括 driver, master 和 executor进程，都在JVM中运行。使用Scala编写的Spark程序编译为Java字节码在JVM上运行。</p>
</li>
<li><p>区分Spark运行时应用程序组件 和运行它们的位置和节点类型是很重要的。使用不同的部署模式，这些组件可能运行在不同的位置，所以不要以物理节点或实例的形式考虑这些组件。</p>
</li>
</ol>
<h2 id="1-Spark-Driver"><a href="#1-Spark-Driver" class="headerlink" title="1.  Spark Driver"></a>1.  Spark Driver</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;Spark 应用程序由一个 driver 进程（驱动程序）和一组 executor 进程组成。Spark 应用程序的生命周期从 Spark Driver 程序开始（和结束）。driver 进程负责运行你的 main 函数，此进程位于集群中的一个 节点上。主要负责三件事：</p>
<ol>
<li>维护有关 Spark 应用程序的信息；</li>
<li>响应用户的程序或输入；</li>
<li>分配和调度 executor 的 task 和资源。</li>
</ol>
<p>executors 进程实际执行 driver 分配给他们的工作。这意味着每个 executor 主要负责两件事：</p>
<ol>
<li>执行由驱动程序分配给它的代码。</li>
<li>将执行器 executor 的计算状态报告给 driver 节点。</li>
</ol>
<h3 id="1-1-SparkContext"><a href="#1-1-SparkContext" class="headerlink" title="1.1 SparkContext"></a>1.1 SparkContext</h3><p>Spark Driver 程序负责创建 SparkContext。 SparkContext 在 Spark Shell 中对应的变量名为 sc，用于连接 Spark 集群，是与 Spark 集群交互的入口。SparkContext 在 Spark 应用程序（包括 Spark Shell）的开始实例化，并用于整个程序。</p>
<h3 id="1-2-应用程序执行计划"><a href="#1-2-应用程序执行计划" class="headerlink" title="1.2 应用程序执行计划"></a>1.2 应用程序执行计划</h3><p>Driver 程序的主要功能之一是规划应用程序的执行。驱动程序接受所有请求的 transformation 和 action 操作，并创建一个有向无环图（DAG）。<br><strong>注</strong>：DAG  是计算机科学中常用的表示数据流及其依赖关系的数学结构。DAGs 包含节点和边，节点表示执行计划中的步骤。DAG中的边以定向的方式将一个节点连接到另一个顶点，这样就不会出现 循环引用。</p>
<p>DAG 由 task 和 stages 组成。task 是 Spark 程序中可调度工作的最小单位。stage是一组可以一起运行的task。多个stage之间是相互依存的 。shuffle是划分stage的依据。</p>
<p>在进程调度意义上，DAGs 并不是 Spark 独有的。例如，它们被用于其他大数据生态系统项目，如 Tez、Drill 和 Presto 的任务调度。DAGs 是 Spark 的基础！！！</p>
<h3 id="1-3-应用程序的调度"><a href="#1-3-应用程序的调度" class="headerlink" title="1.3 应用程序的调度"></a>1.3 应用程序的调度</h3><p>driver 程序还协调 DAG 中定义的 stage 和 task 的运行。在调度和运行 task 时涉及的主要driver 程序活动包括：</p>
<ul>
<li>跟踪可用资源以执行 task</li>
<li>调度任务，以便在可能的情况下 “接近”数据运行——数据本地性</li>
<li>协调数据在 stages 之间的移动</li>
</ul>
<h3 id="1-4-其他功能"><a href="#1-4-其他功能" class="headerlink" title="1.4 其他功能"></a>1.4 其他功能</h3><p>除了计划和编排 Spark 程序的执行之外，驱动程序还负责从应用程序返回结果。<br>driver 程序在4040端口上自动创建了应用程序 UI。如果在同一个主机上启动后续应用程序，则会为应用程序 UI 使用连续的端口（例如 4041, 4042 等）。</p>
<h2 id="2-Executor-和-worker"><a href="#2-Executor-和-worker" class="headerlink" title="2. Executor 和 worker"></a>2. Executor 和 worker</h2><p>Spark executor 是运行来自 Spark DAG 的task 进程。executor 在 Spark 集群中的worker 节点上获取 CPU和内存等计算资源。executor 专用于特定的 Spark 应用程序，并在 应用程序完成时终止。在 Spark 程序中，Spark executor 可以运行成百上千个 task。</p>
<p>通常情况下，worker 节点（承载 executor 进程）具有有限或固定数量的 executor。因此，一个 spark 集群（包括一定数量的服务器节点）具有有限数量的 executor，可以分配它们来运行 Spark 任务。</p>
<p>Spark executor 驻留在 JVM 中。executor 的 JVM 分配了一个堆内存，这是一个用于存储和管理对象的专用内存空间。堆内存的大小由 spark 配置文件 spark-default.xml 中的 spark.executor.memory 属性确定，或者 由提交应用程序时 spark-submit 的参数 –executor-memroy  确定。</p>
<p>worker 和 executor 只知道分配给他们的 task，而 driver 程序负责理解组成应用程序的完整 task 集合它们各自的依赖关系。</p>
<h2 id="3-Master-和-Cluster-Manager"><a href="#3-Master-和-Cluster-Manager" class="headerlink" title="3. Master 和 Cluster Manager"></a>3. Master 和 Cluster Manager</h2><p>Spark driver 程序计划并协调运行 Spark 应用程序所需的 task 集。task 本身在 executor 中运行，executor 驻留在 worker 节点上。</p>
<p>Master 和 Cluster Manager 是监控、分配、回收集群（Executor 运行的节点）资源的核心进程，Master 和 Cluster Manager 可以是各自独立的进程（Spark On YARN），也可以组合成一个进程（Standalone 运行模式）。</p>
<h3 id="3-1-Master"><a href="#3-1-Master" class="headerlink" title="3.1 Master"></a>3.1 Master</h3><p>Spark master 是用于请求集群中的资源并将这些资源提供给 Spark driver 程序的进程。在两种部署模式中，master 节点都与 worker 节点或slave 节点协商资源或容器，并跟踪 它们的状态并监视它们的进展。</p>
<p>Spark master 进程在 master 进程所在主机上的端口 8080 上，提供 web 用户界面。</p>
<p><strong>注</strong>：要区分 driver 进程和 master 进程在 Spark 程序运行时的作用。master 只是请求 资源，并使这些资源在应用程序的生命周期内对驱动程序可用。尽管 master 监控这些资源的状态和健康状况，但是它不参与应用程序的执行以及 task 和 stage 的协调。</p>
<h3 id="3-2-Cluster-Manager（集群管理器）"><a href="#3-2-Cluster-Manager（集群管理器）" class="headerlink" title="3.2 Cluster Manager（集群管理器）"></a>3.2 Cluster Manager（集群管理器）</h3><p>Cluster Manager 进程负责监控分配给 worker 节点上的资源，这些资源是 master 进程请求分配的。然后，master 以 Executor 的形式将这些集群资源提供给 driver 程序。如前所述，Cluster Manager可以独立于 master 进程（Spark On YARN），也可以组合成一个进程（Standalone 运行模式）。</p>

    
  </div>

</article>


   
  <div class="text-center donation">
    <div class="inner-donation">
      <span class="btn-donation">支持一下</span>
      <div class="donation-body">
        <div class="tip text-center">扫一扫，支持forsigner</div>
        <ul>
        
          <li class="item">
            
              <span>微信扫一扫</span>
            
            <img src="/images/qr-wechat.png" alt="">
          </li>
        
          <li class="item">
            
              <span>支付宝扫一扫</span>
            
            <img src="/images/qr-alipay.png" alt="">
          </li>
        
        </ul>
      </div>
    </div>
  </div>


   
  <div class="box-prev-next clearfix">
    <a class="hide pull-left" href="/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2019/07/23/Hadoop-集群-HA-架构配置/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>




</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/atom.xml"
              rel="noopener noreferrer"
              target="_blank"
              >
              RSS
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    

    
    

    

    
    

    

<!-- Gitalk评论插件通用代码 -->
<div id="gitalk-container"></div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script>
const gitalk = new Gitalk({
  clientID: 'abd8d437b0756846f505',
  clientSecret: '51790d6ce6c336ad28f7b813346571938ac3a510',
  repo: 'gitalk_comment',
  owner: 'Miracle-Xing',
  // 在这里设置一下截取前50个字符串, 这是因为 github 对 label 的长度有了要求, 如果超过
  // 50个字符串则会报错.
  // id: location.pathname.split('/').pop().substring(0, 49),
  id: location.pathname,
  admin: ['Miracle-Xing'],
  // facebook-like distraction free mode
  distractionFreeMode: false
})
gitalk.render('gitalk-container')
</script>
<!-- Gitalk代码结束 -->



  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
